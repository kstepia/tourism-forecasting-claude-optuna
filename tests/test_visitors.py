# tests/test_visitors.py
"""
ì œì£¼ ë°©ë¬¸ê° ë°ì´í„° í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸
ìµœê·¼ 7ì¼ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í¬ë¡¤ë§ í’ˆì§ˆ ë° ì•ˆì •ì„± ê²€ì¦
"""

import unittest
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import sys
import os
from pathlib import Path
import tempfile
import logging

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from scripts.visitors.fetch_visitors import JejuVisitorsCrawler

# í…ŒìŠ¤íŠ¸ìš© ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.WARNING)  # í…ŒìŠ¤íŠ¸ ì¤‘ ë¡œê·¸ ìµœì†Œí™”

class TestJejuVisitorsCrawler(unittest.TestCase):
    """ì œì£¼ ë°©ë¬¸ê° ë°ì´í„° í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    @classmethod
    def setUpClass(cls):
        """í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤ ì´ˆê¸°í™” - ìµœê·¼ 7ì¼ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±"""
        print("ğŸ” ì œì£¼ ë°©ë¬¸ê° í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        print("ğŸ“… ìµœê·¼ 7ì¼ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        
        cls.crawler = JejuVisitorsCrawler()
        cls.test_data_path = project_root / "tests" / "test_visitor_data.csv"
        
        # í…ŒìŠ¤íŠ¸ìš© ì„ì‹œ ë‹¤ìš´ë¡œë“œ ë””ë ‰í† ë¦¬ ì„¤ì •
        cls.temp_dir = tempfile.mkdtemp()
        os.environ["DOWNLOAD_DIR"] = cls.temp_dir
        
        # ìµœê·¼ 7ì¼ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘
        cls._collect_test_data()
        
    @classmethod
    def _collect_test_data(cls):
        """ìµœê·¼ 7ì¼ ë°©ë¬¸ê° ë°ì´í„° ìˆ˜ì§‘"""
        try:
            # í¬ë¡¤ëŸ¬ ì‹¤í–‰í•˜ì—¬ ìµœì‹  ë°ì´í„° ìˆ˜ì§‘
            all_data = cls.crawler.run()
            
            if not all_data.empty:
                # ìµœê·¼ 7ì¼ ë°ì´í„°ë§Œ í•„í„°ë§
                end_date = datetime.now().date()
                start_date = end_date - timedelta(days=7)
                
                # ë‚ ì§œ ì»¬ëŸ¼ì´ datetime íƒ€ì…ì¸ì§€ í™•ì¸
                if 'date' in all_data.columns:
                    all_data['date'] = pd.to_datetime(all_data['date'])
                    recent_data = all_data[
                        (all_data['date'].dt.date >= start_date) & 
                        (all_data['date'].dt.date <= end_date)
                    ].copy()
                    
                    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì €ì¥ (CSV í˜•ì‹)
                    recent_data.to_csv(cls.test_data_path, index=False, encoding='utf-8')
                    cls.test_data = recent_data
                    
                    print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(recent_data)}ê±´")
                    print(f"ğŸ“Š ë°ì´í„° ë²”ìœ„: {recent_data['date'].min()} ~ {recent_data['date'].max()}")
                else:
                    # ë¹ˆ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì´ˆê¸°í™”
                    cls.test_data = pd.DataFrame()
                    print("âš ï¸  ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            else:
                cls.test_data = pd.DataFrame()
                print("âš ï¸  ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŒ")
                
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            cls.test_data = pd.DataFrame()
    
    def test_crawler_initialization(self):
        """í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        self.assertIsInstance(self.crawler, JejuVisitorsCrawler)
        self.assertGreater(len(self.crawler.sites), 0)
        self.assertIn('visitjeju', self.crawler.sites)
        self.assertIn('ijto', self.crawler.sites)
        
    def test_sites_configuration(self):
        """ì‚¬ì´íŠ¸ ì„¤ì • í…ŒìŠ¤íŠ¸"""
        expected_sites = ['ijto', 'datahub', 'tour_kr', 'visitjeju', 'kto', 'kosis', 'data_go_kr', 'jeju_gov']
        
        for site in expected_sites:
            self.assertIn(site, self.crawler.sites, f"{site} ì‚¬ì´íŠ¸ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            self.assertTrue(self.crawler.sites[site].startswith('http'), f"{site} URLì´ ìœ íš¨í•˜ì§€ ì•ŠìŒ")
    
    def test_retry_strategies(self):
        """403 ìš°íšŒ ì „ëµ í…ŒìŠ¤íŠ¸"""
        expected_strategies = ['basic', 'user_agent_rotation', 'session_reset', 'delay_retry', 'referer_header']
        
        for strategy in expected_strategies:
            self.assertIn(strategy, self.crawler.retry_strategies)
    
    def test_headers_generation(self):
        """HTTP í—¤ë” ìƒì„± í…ŒìŠ¤íŠ¸"""
        # ê¸°ë³¸ í—¤ë” í…ŒìŠ¤íŠ¸
        headers = self.crawler._get_headers('basic')
        self.assertIn('User-Agent', headers)
        self.assertIn('Accept', headers)
        
        # User-Agent ë¡œí…Œì´ì…˜ í…ŒìŠ¤íŠ¸
        headers_rotation = self.crawler._get_headers('user_agent_rotation')
        self.assertIn('User-Agent', headers_rotation)
        
        # Referer í—¤ë” í…ŒìŠ¤íŠ¸
        headers_referer = self.crawler._get_headers('referer_header', 'https://google.com')
        self.assertIn('Referer', headers_referer)
        self.assertEqual(headers_referer['Referer'], 'https://google.com')
    
    def test_collected_data_structure(self):
        """ìˆ˜ì§‘ëœ ë°ì´í„° êµ¬ì¡° í…ŒìŠ¤íŠ¸"""
        if self.test_data.empty:
            self.skipTest("í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŒ")
        
        # í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
        required_columns = ['date', 'visitors', 'source']
        for col in required_columns:
            self.assertIn(col, self.test_data.columns, f"í•„ìˆ˜ ì»¬ëŸ¼ {col}ì´ ì—†ìŒ")
        
        # ë°ì´í„° íƒ€ì… í™•ì¸
        self.assertTrue(pd.api.types.is_datetime64_any_dtype(self.test_data['date']), "ë‚ ì§œ ì»¬ëŸ¼ì´ datetime íƒ€ì…ì´ ì•„ë‹˜")
        self.assertTrue(pd.api.types.is_numeric_dtype(self.test_data['visitors']), "ë°©ë¬¸ê° ìˆ˜ê°€ ìˆ«ì íƒ€ì…ì´ ì•„ë‹˜")
    
    def test_data_quality(self):
        """ë°ì´í„° í’ˆì§ˆ í…ŒìŠ¤íŠ¸"""
        if self.test_data.empty:
            self.skipTest("í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŒ")
        
        # ê²°ì¸¡ê°’ í™•ì¸
        self.assertFalse(self.test_data['date'].isna().any(), "ë‚ ì§œì— ê²°ì¸¡ê°’ ì¡´ì¬")
        self.assertFalse(self.test_data['visitors'].isna().any(), "ë°©ë¬¸ê° ìˆ˜ì— ê²°ì¸¡ê°’ ì¡´ì¬")
        
        # ë°©ë¬¸ê° ìˆ˜ ë²”ìœ„ í™•ì¸ (í•©ë¦¬ì ì¸ ë²”ìœ„)
        min_visitors = self.test_data['visitors'].min()
        max_visitors = self.test_data['visitors'].max()
        
        self.assertGreater(min_visitors, 0, "ë°©ë¬¸ê° ìˆ˜ê°€ 0 ì´í•˜")
        self.assertLess(max_visitors, 10000000, "ë°©ë¬¸ê° ìˆ˜ê°€ ë¹„í˜„ì‹¤ì ìœ¼ë¡œ í¼")
        
        # ìŒìˆ˜ ê°’ í™•ì¸
        negative_count = (self.test_data['visitors'] < 0).sum()
        self.assertEqual(negative_count, 0, "ìŒìˆ˜ ë°©ë¬¸ê° ìˆ˜ ì¡´ì¬")
    
    def test_date_range_validation(self):
        """ë‚ ì§œ ë²”ìœ„ ê²€ì¦ í…ŒìŠ¤íŠ¸"""
        if self.test_data.empty:
            self.skipTest("í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŒ")
        
        # ìµœê·¼ 7ì¼ ë²”ìœ„ í™•ì¸
        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=7)
        
        dates = pd.to_datetime(self.test_data['date']).dt.date
        
        # ëª¨ë“  ë‚ ì§œê°€ ì§€ì •ëœ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
        valid_dates = (dates >= start_date) & (dates <= end_date)
        invalid_count = (~valid_dates).sum()
        
        self.assertEqual(invalid_count, 0, f"ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ ë‚ ì§œ {invalid_count}ê°œ ë°œê²¬")
    
    def test_source_diversity(self):
        """ë°ì´í„° ì†ŒìŠ¤ ë‹¤ì–‘ì„± í…ŒìŠ¤íŠ¸"""
        if self.test_data.empty:
            self.skipTest("í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŒ")
        
        # ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ ë°ì´í„°ê°€ ìˆ˜ì§‘ë˜ì—ˆëŠ”ì§€ í™•ì¸
        sources = self.test_data['source'].unique()
        self.assertGreater(len(sources), 0, "ë°ì´í„° ì†ŒìŠ¤ê°€ ì—†ìŒ")
        
        # ê° ì†ŒìŠ¤ë³„ ë°ì´í„° ê°œìˆ˜ ì¶œë ¥
        source_counts = self.test_data['source'].value_counts()
        print("\nğŸ“ˆ ì†ŒìŠ¤ë³„ ë°ì´í„° ê°œìˆ˜:")
        for source, count in source_counts.items():
            print(f"  {source}: {count}ê±´")
    
    def test_duplicate_handling(self):
        """ì¤‘ë³µ ë°ì´í„° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        if self.test_data.empty:
            self.skipTest("í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŒ")
        
        # ê°™ì€ ë‚ ì§œì˜ ì¤‘ë³µ ë°ì´í„° í™•ì¸
        duplicate_dates = self.test_data.groupby('date').size()
        max_records_per_date = duplicate_dates.max()
        
        # í•˜ë£¨ì— ë„ˆë¬´ ë§ì€ ë ˆì½”ë“œê°€ ìˆìœ¼ë©´ ì¤‘ë³µ ì²˜ë¦¬ê°€ ì œëŒ€ë¡œ ì•ˆëœ ê²ƒ
        self.assertLessEqual(max_records_per_date, 10, "ê°™ì€ ë‚ ì§œì— ë„ˆë¬´ ë§ì€ ë ˆì½”ë“œ ì¡´ì¬")
    
    def test_data_completeness(self):
        """ë°ì´í„° ì™„ì„±ë„ í…ŒìŠ¤íŠ¸"""
        if self.test_data.empty:
            self.skipTest("í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŒ")
        
        # ìµœê·¼ 7ì¼ ì¤‘ ë°ì´í„°ê°€ ìˆëŠ” ë‚  ìˆ˜ í™•ì¸
        unique_dates = self.test_data['date'].dt.date.nunique()
        
        # ì ì–´ë„ ìµœê·¼ 3ì¼ ì´ìƒì˜ ë°ì´í„°ê°€ ìˆì–´ì•¼ í•¨
        self.assertGreaterEqual(unique_dates, 1, "ì¶©ë¶„í•œ ë‚ ì§œì˜ ë°ì´í„°ê°€ ì—†ìŒ")
        
        print(f"\nğŸ“… ìˆ˜ì§‘ëœ ë‚ ì§œ ìˆ˜: {unique_dates}ì¼")
    
    def test_harmonization_logic(self):
        """ë°ì´í„° ì •í•© ë¡œì§ í…ŒìŠ¤íŠ¸"""
        # í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„° ìƒì„±
        daily_data = pd.DataFrame({
            'date': [datetime(2024, 1, 1), datetime(2024, 1, 2)],
            'visitors': [1000, 1500],
            'source': ['daily', 'daily'],
            'data_type': ['daily', 'daily']
        })
        
        monthly_data = pd.DataFrame({
            'date': [datetime(2024, 1, 1), datetime(2024, 1, 3)],
            'visitors': [1200, 1800],
            'source': ['monthly', 'monthly'],
            'data_type': ['monthly', 'monthly']
        })
        
        # ì •í•© í…ŒìŠ¤íŠ¸
        harmonised = self.crawler.harmonise_data(daily_data, monthly_data)
        
        self.assertFalse(harmonised.empty, "ì •í•©ëœ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ")
        self.assertEqual(len(harmonised), 3, "ì •í•©ëœ ë°ì´í„° ê°œìˆ˜ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦„")
        
        # ì¤‘ë³µ ì œê±° í™•ì¸ (1ì›” 1ì¼ì€ daily ë°ì´í„°ê°€ ìš°ì„ ë˜ì–´ì•¼ í•¨)
        jan_1_data = harmonised[harmonised['date'] == datetime(2024, 1, 1)]
        self.assertEqual(len(jan_1_data), 1, "ì¤‘ë³µ ì œê±°ê°€ ì œëŒ€ë¡œ ë˜ì§€ ì•ŠìŒ")
        self.assertEqual(jan_1_data.iloc[0]['visitors'], 1000, "ì¼ë³„ ë°ì´í„° ìš°ì„ ìˆœìœ„ê°€ ì ìš©ë˜ì§€ ì•ŠìŒ")
    
    @classmethod
    def tearDownClass(cls):
        """í…ŒìŠ¤íŠ¸ ì¢…ë£Œ í›„ ì •ë¦¬"""
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬
        import shutil
        if hasattr(cls, 'temp_dir') and os.path.exists(cls.temp_dir):
            shutil.rmtree(cls.temp_dir)
        
        print("\nğŸ§¹ í…ŒìŠ¤íŠ¸ ì •ë¦¬ ì™„ë£Œ")

class TestDataValidation(unittest.TestCase):
    """ë°ì´í„° ê²€ì¦ ì „ìš© í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def setUp(self):
        """ê° í…ŒìŠ¤íŠ¸ ì „ ì‹¤í–‰"""
        self.test_data_path = project_root / "tests" / "test_visitor_data.csv"
        
        if self.test_data_path.exists():
            self.test_data = pd.read_csv(self.test_data_path)
        else:
            self.test_data = pd.DataFrame()
    
    def test_statistical_outliers(self):
        """í†µê³„ì  ì´ìƒê°’ íƒì§€ í…ŒìŠ¤íŠ¸"""
        if self.test_data.empty:
            self.skipTest("í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŒ")
        
        visitors = self.test_data['visitors']
        
        # IQR ë°©ë²•ìœ¼ë¡œ ì´ìƒê°’ íƒì§€
        Q1 = visitors.quantile(0.25)
        Q3 = visitors.quantile(0.75)
        IQR = Q3 - Q1
        
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        outliers = visitors[(visitors < lower_bound) | (visitors > upper_bound)]
        outlier_percentage = len(outliers) / len(visitors) * 100
        
        # ì´ìƒê°’ì´ ì „ì²´ì˜ 10% ì´í•˜ì—¬ì•¼ í•¨
        self.assertLess(outlier_percentage, 10, f"ì´ìƒê°’ì´ ë„ˆë¬´ ë§ìŒ: {outlier_percentage:.1f}%")
        
        print(f"\nğŸ“Š í†µê³„ ì •ë³´:")
        print(f"  í‰ê· : {visitors.mean():,.0f}")
        print(f"  ì¤‘ì•™ê°’: {visitors.median():,.0f}")
        print(f"  í‘œì¤€í¸ì°¨: {visitors.std():,.0f}")
        print(f"  ì´ìƒê°’: {len(outliers)}ê°œ ({outlier_percentage:.1f}%)")
    
    def test_data_consistency(self):
        """ë°ì´í„° ì¼ê´€ì„± í…ŒìŠ¤íŠ¸"""
        if self.test_data.empty:
            self.skipTest("í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŒ")
        
        # ê°™ì€ ì†ŒìŠ¤ì—ì„œ ì˜¤ëŠ” ë°ì´í„°ì˜ ì¼ê´€ì„± í™•ì¸
        for source in self.test_data['source'].unique():
            source_data = self.test_data[self.test_data['source'] == source]
            
            if len(source_data) > 1:
                # ê°™ì€ ì†ŒìŠ¤ì˜ ë°©ë¬¸ê° ìˆ˜ ë³€ë™ì´ ë„ˆë¬´ í¬ì§€ ì•Šì€ì§€ í™•ì¸
                visitors_std = source_data['visitors'].std()
                visitors_mean = source_data['visitors'].mean()
                
                if visitors_mean > 0:
                    cv = visitors_std / visitors_mean  # ë³€ë™ê³„ìˆ˜
                    self.assertLess(cv, 5.0, f"{source} ì†ŒìŠ¤ì˜ ë°ì´í„° ë³€ë™ì´ ë„ˆë¬´ í¼ (CV: {cv:.2f})")

def create_test_suite():
    """í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ìƒì„±"""
    test_suite = unittest.TestSuite()
    
    # í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì¶”ê°€
    crawler_tests = unittest.TestLoader().loadTestsFromTestCase(TestJejuVisitorsCrawler)
    test_suite.addTests(crawler_tests)
    
    # ë°ì´í„° ê²€ì¦ í…ŒìŠ¤íŠ¸ ì¶”ê°€
    validation_tests = unittest.TestLoader().loadTestsFromTestCase(TestDataValidation)
    test_suite.addTests(validation_tests)
    
    return test_suite

def run_tests():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸ§ª ì œì£¼ ë°©ë¬¸ê° ë°ì´í„° í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ìƒì„± ë° ì‹¤í–‰
    test_suite = create_test_suite()
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    print("\n" + "=" * 60)
    print(f"ğŸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print(f"âœ… ì„±ê³µ: {result.testsRun - len(result.failures) - len(result.errors)}ê°œ")
    
    if result.failures:
        print(f"âŒ ì‹¤íŒ¨: {len(result.failures)}ê°œ")
    
    if result.errors:
        print(f"ğŸ’¥ ì˜¤ë¥˜: {len(result.errors)}ê°œ")
    
    return result.wasSuccessful()

if __name__ == "__main__":
    success = run_tests()
    sys.exit(0 if success else 1)